{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NC Water Scraper\n",
    "This notebook consolidates water withdrawal, discharge, and transfer data from NCDEQs Water Withdrawal & Transfer Registry ([link](http://www.ncwater.org/Permits_and_Registration/Water_Withdrawal_and_Transfer_Registration/report)). The sequence of analysis is as follows:\n",
    "* First data from the registry's front page (link above) is scraped into a dataframe listing Registered Owner, Facility Name, Status, and Facility ID. \n",
    "* Then, using each entry's facility ID to access its annual report, data are scraped - one facility and one year at a time - to compile a table listing monthly withdrawals, discharges, and transfers for a set of years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os,requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Create a dataframe of sites in the registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the contents of the base web page into a 'soup' object for scraping\n",
    "baseURL = 'http://www.ncwater.org/Permits_and_Registration/Water_Withdrawal_and_Transfer_Registration/report'\n",
    "r = requests.get(baseURL)\n",
    "soup = BeautifulSoup(r.text,'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following works with the current format of the web page. If it changes, this may have to be revised. Here we select the items in the web form containing the data we want to extract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the main table, identified with the id=main\n",
    "trTable = soup.find_all(id=\"content\")[0]\n",
    "type(trTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the second table contained in the table selected above\n",
    "dataTable = trTable.find_all('table')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all rows in the table selected above; these contain the data we want\n",
    "rows = dataTable.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Owner</th>\n",
       "      <th>Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Owner, Name, Status, Code]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize the dataframe that will hold our data\n",
    "colNames = ['Owner','Name','Status','Code']\n",
    "dfSites = pd.DataFrame(columns=colNames)\n",
    "dfSites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Owner</th>\n",
       "      <th>Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3M Company</td>\n",
       "      <td>3M Pittsboro Mine</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0831-0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAcme</td>\n",
       "      <td>AAcme</td>\n",
       "      <td>Draft</td>\n",
       "      <td>0847-0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alamac American Knits, LLC</td>\n",
       "      <td>Alamac American Knits</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0292-0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alamance Country Club</td>\n",
       "      <td>Alamance Country Club</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0043-0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American &amp; Efird, Inc.</td>\n",
       "      <td>Plant 15</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0004-0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Owner                   Name     Status       Code\n",
       "0                  3M Company      3M Pittsboro Mine  Completed  0831-0001\n",
       "1                     AAAAcme                  AAcme      Draft  0847-0001\n",
       "2  Alamac American Knits, LLC  Alamac American Knits  Completed  0292-0001\n",
       "3       Alamance Country Club  Alamance Country Club  Completed  0043-0001\n",
       "4      American & Efird, Inc.               Plant 15  Completed  0004-0001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loop through each row (skipping the first, which contains headers), extracting data into our data frame\n",
    "for row in rows[1:]:\n",
    "    \n",
    "    #Create a collection of columns for the current row\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    #Construct a dictionary of the items we want\n",
    "    dictR = {'Owner':columns[0].string,\n",
    "             'Name':columns[1].string,\n",
    "             'Status':columns[2].string,\n",
    "             'Code':columns[3].find(\"a\")['href'].split(\"/\")[-2]}\n",
    "    \n",
    "    #Append these data to our dataframe\n",
    "    dfSites = dfSites.append(dictR,ignore_index=True)\n",
    "    \n",
    "dfSites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folder to hold all the downloads\n",
    "outFolder = \"NCDEQ\"\n",
    "if not os.path.exists(outFolder): os.mkdir(outFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save contents to a file...\n",
    "dfSites.to_csv(\"NCDEQ/WithdrawalMaster.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Extract report data for each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstackTable(dfStacked):\n",
    "    '''\n",
    "    Unstacks monthly tables presented in 2-column formats into a \n",
    "    single column format. For example:\n",
    "    | Jan | Jul | \n",
    "    | Feb | Aug |\n",
    "    | Mar | Sep | \n",
    "    | Apr | Oct | \n",
    "    | May | Nov | \n",
    "    | Jun | Dec | \n",
    "    is converted to a single column with associated data attached. \n",
    "    '''\n",
    "    #Copy the table\n",
    "    df2 = dfStacked.copy(deep=True)\n",
    "    \n",
    "    #Convert the first row to columns, then drop the row\n",
    "    colNames = df2.iloc[0]\n",
    "    df2.columns = colNames\n",
    "    df2.drop(0,inplace=True)\n",
    "\n",
    "    #Convert two column format to one\n",
    "    df2a = df2.iloc[:,:4]\n",
    "    df2b = df2.iloc[:,4:]\n",
    "    df2 = df2a.append(df2b)\n",
    "\n",
    "    #Set month to be the index\n",
    "    df2.set_index(\"Month\",inplace=True)\n",
    "\n",
    "    #Convert data types for columns 2, 3, and 4 (days, avg, max)\n",
    "    df2.iloc[:,0] = df2.iloc[:,0].fillna(0).astype(int)\n",
    "    df2.iloc[:,1] = df2.iloc[:,1].astype(float)\n",
    "    df2.iloc[:,2] = df2.iloc[:,2].astype(float)\n",
    "    \n",
    "    #Return the table\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScrapeSite(siteID, year, first=False):\n",
    "    \n",
    "    #--DATA EXTRACTION--\n",
    "    #Construct the URL\n",
    "    siteURL = 'http://www.ncwater.org/Permits_and_Registration/Water_Withdrawal_and_Transfer_Registration/report/view/{0}/{1}'.format(siteID,year)\n",
    "\n",
    "    #Extract all tables from the URL into a collection of dataframes\n",
    "    dfs = pd.read_html(siteURL,na_values='NaN')\n",
    "\n",
    "    #Separate tables into labeled variables, unstacking as needed\n",
    "    dfFacility = dfs[2]                  # Information on the facility\n",
    "    dfWithdrawal = unstackTable(dfs[3])  # Monthly withdrawal data   \n",
    "    dfSource = dfs[4]                    # Information on where water was drawn\n",
    "    dfDischarge = unstackTable(dfs[5])   # Monthly discharge data \n",
    "    dfDischargeMethod = dfs[6]           # Information on type and amounts of discharge\n",
    "    dfTransferDescription = dfs[7]       # Information on source and destination of transfers\n",
    "    dfTransfer= unstackTable(dfs[8])     # Monthly transfer data\n",
    "\n",
    "    #Extract facility information into variables\n",
    "    registrant = dfFacility.iloc[0,1]\n",
    "    facility_name = dfFacility.iloc[0,1]\n",
    "    county = dfFacility.iloc[2,1]\n",
    "    subbasin= dfFacility.iloc[2,3]\n",
    "    facility_type = dfFacility.iloc[1,3]\n",
    "    \n",
    "    #--MONTHLY VOLUME DATA----------------------\n",
    "    #Combine monthly withdrawal, discharge, and transfer tables\n",
    "    dfSiteData = pd.concat([dfWithdrawal,dfDischarge,dfTransfer], axis=1).reset_index()\n",
    "\n",
    "    #Add site information as columns\n",
    "    dfSiteData['SiteID'] = siteID\n",
    "    dfSiteData['Year'] = year\n",
    "    dfSiteData['Registrant'] = registrant\n",
    "    dfSiteData['Facility'] = facility_name\n",
    "    dfSiteData['Type'] = facility_type\n",
    "    dfSiteData['County'] = county\n",
    "    dfSiteData['Subbasin'] = subbasin\n",
    "\n",
    "    #Rearrange columns\n",
    "    columns = dfSiteData.columns.tolist()[10:] + dfSiteData.columns.tolist()[:10]\n",
    "    dfSiteData = dfSiteData[columns]\n",
    "\n",
    "    #--WITHDRAWAL INFO--------------------------\n",
    "    dfSource = dfs[4].copy(deep=True)\n",
    "    dfSource.columns = ('Name','Type','AvgDaily','DaysUsed','Capacity_MGD')\n",
    "    dfSource.drop(0,inplace=True)\n",
    "    dfSource.insert(0,'SiteID',siteID)\n",
    "    dfSource.insert(1,'Year',year)    \n",
    "    dfSource.insert(2,'FacilityType',facility_type)\n",
    "    dfSource.insert(3,'County',county)\n",
    "    dfSource.insert(4,'Subbasin',subbasin)\n",
    "\n",
    "    #--DISCHARGE INFO-------------------------\n",
    "    dfDischargeMethod = dfs[6].copy(deep=True)\n",
    "    dfDischargeMethod.columns = ('Permit','Type','AvgDaily','DaysUsed','Capacity_MGD')\n",
    "    dfDischargeMethod.drop(0,inplace=True)\n",
    "    dfDischargeMethod.insert(0,'SiteID',siteID)\n",
    "    dfDischargeMethod.insert(1,'Year',year)\n",
    "    dfDischargeMethod.insert(2,'FacilityType',facility_type)\n",
    "    dfDischargeMethod.insert(3,'County',county)\n",
    "    dfDischargeMethod.insert(4,'Subbasin',subbasin)\n",
    "    \n",
    "    #--TRANSFER INFO------------------------------\n",
    "    dfTransferDescription = dfs[7].copy(deep=True)\n",
    "    dfTransferDescription.columns = ('Description','SourceBasin','ReceivingBasin','Capacity')\n",
    "    dfTransferDescription.drop(0,inplace=True)\n",
    "    dfTransferDescription.insert(0,'SiteID',siteID)\n",
    "    dfTransferDescription.insert(1,'Year',year)\n",
    "    dfTransferDescription.insert(2,'FacilityType',facility_type)\n",
    "    dfTransferDescription.insert(3,'County',county)\n",
    "    dfTransferDescription.insert(4,'Subbasin',subbasin)    \n",
    "\n",
    "    #-WRITE DATA TO OUTPUT FILES------------------\n",
    "    outCSV1 = \"NCDEQ/MonthlyVolumeData.csv\"\n",
    "    outCSV2 = \"NCDEQ/WithdrawalSourceData.csv\"\n",
    "    outCSV3 = \"NCDEQ/DischargeMethods.csv\"\n",
    "    outCSV4 = \"NCDEQ/TransferInfo.csv\"\n",
    "    \n",
    "    #If this is the first table, write to new csv files\n",
    "    if first:\n",
    "        outputType = 'w' #Write to new file\n",
    "        head = True      #Include header row\n",
    "    else: \n",
    "        outputType = 'a' #Append to existing file\n",
    "        head = False     #Don't include headers\n",
    "        \n",
    "    #Write monthly volume data to new file\n",
    "    with open(outCSV1,outputType) as outFile:\n",
    "        dfSiteData.to_csv(outFile,header=head,index=False)\n",
    "\n",
    "    #Write source info data to new file  \n",
    "    with open(outCSV2, outputType) as outFile:\n",
    "        dfSource.to_csv(outFile,header=head,index=False)\n",
    "\n",
    "    #Write discharge info data to new file  \n",
    "    with open(outCSV3, outputType) as outFile:\n",
    "        dfDischargeMethod.to_csv(outFile,header=head,index=False)\n",
    "\n",
    "    #Write transfer info data to new file  \n",
    "    with open(outCSV4, outputType) as outFile:\n",
    "        dfTransferDescription.to_csv(outFile,header=head,index=False)\n",
    "            \n",
    "    return (outCSV1,outCSV2, outCSV3, outCSV4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0831-0001: 2010..."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Plan shapes are not aligned",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8ef889e704b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2010\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutFiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mScrapeSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msiteID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirstFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mfirstFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-5c1913b8fb14>\u001b[0m in \u001b[0;36mScrapeSite\u001b[1;34m(siteID, year, first)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#Separate tables into labeled variables, unstacking as needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdfFacility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m                  \u001b[1;31m# Information on the facility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdfWithdrawal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munstackTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Monthly withdrawal data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mdfSource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m                    \u001b[1;31m# Information on where water was drawn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdfDischarge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munstackTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Monthly discharge data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-abdf7e05d362>\u001b[0m in \u001b[0;36munstackTable\u001b[1;34m(dfStacked)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdf2a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mdf2b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#Set month to be the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\gis\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   7745\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7746\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7747\u001b[1;33m             \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7748\u001b[0m         )\n\u001b[0;32m   7749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\gis\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    285\u001b[0m     )\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\gis\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 503\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             )\n\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\gis\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_units\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconcat_plan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\gis\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m_combine_concat_plans\u001b[1;34m(plans, concat_axis)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mnum_ended\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_ended\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Plan shapes are not aligned\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mplacements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnext_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Plan shapes are not aligned"
     ]
    }
   ],
   "source": [
    "#Set flag for the first file (to create a new output)\n",
    "firstFile = True\n",
    "\n",
    "#Loop through each site ID and scrape it's data\n",
    "for index, row in dfSites.iterrows():\n",
    "    \n",
    "    #Skip draft data\n",
    "    if row['Status'] == 'Draft': continue\n",
    "        \n",
    "    #Get the code and loop through years\n",
    "    siteID = row['Code']\n",
    "    print(index,siteID,end=': ')\n",
    "\n",
    "    #Loop through years 2010 to 2017 and scrape the data\n",
    "    for year in range(2010,2018):\n",
    "        print(year,end='...')\n",
    "        outFiles = ScrapeSite(siteID,year,first=firstFile)\n",
    "        firstFile = False\n",
    "    print()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
